<!DOCTYPE html>
<html lang="en-us">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
        <link href='bootstrap.min.css' rel='stylesheet' type='text/css'>
        <title>Training Parallelism - Andrew Szot</title><meta name="Description" content=""><meta property="og:url" content="http://localhost:1313/posts/training_parallelism/">
  <meta property="og:site_name" content="Andrew Szot">
  <meta property="og:title" content="Training Parallelism">
  <meta property="og:description" content="Intro This post shows how to scale training transformer models in terms of batch size, model size and sequence length. First, this post goes over scaling the batch size with multi-GPU and multi-node training. Next, the post details how to scale the model size with training a 7B parameter LLM where training does not fit on a single GPU, but can be trained on 2 GPUs. Finally, the post discusses scaling to a 10,000 token context length when the activations do not on a single GPU.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-25T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-08-25T00:00:00+00:00">
<meta name="twitter:card" content="summary"><meta name="twitter:title" content="Training Parallelism">
<meta name="twitter:description" content="Intro This post shows how to scale training transformer models in terms of batch size, model size and sequence length. First, this post goes over scaling the batch size with multi-GPU and multi-node training. Next, the post details how to scale the model size with training a 7B parameter LLM where training does not fit on a single GPU, but can be trained on 2 GPUs. Finally, the post discusses scaling to a 10,000 token context length when the activations do not on a single GPU.">
<meta name="application-name" content="Andrew Szot">
<meta name="apple-mobile-web-app-title" content="Andrew Szot"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://localhost:1313/posts/training_parallelism/" /><link rel="prev" href="http://localhost:1313/posts/position_embeddings/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Training Parallelism",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/posts\/training_parallelism\/"
        },"genre": "posts","wordcount":  2574 ,
        "url": "http:\/\/localhost:1313\/posts\/training_parallelism\/","datePublished": "2024-08-25T00:00:00+00:00","dateModified": "2024-08-25T00:00:00+00:00","publisher": {
            "@type": "Organization",
            "name": ""},"description": ""
    }
    </script></head>
    <body header-desktop="" header-mobile=""><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : '' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
  <div class="header-wrapper wrap-pad">
    <div class="title-header content">
      <div class="inner" style='display: flex'>
        <a href='/' class='title-link'>
          <h1>Andrew Szot</h1>
        </a>
        <img id='me-picture' src='/landing/me.jpg'>
      </div>
      <div class='side-btns'>
        <a href='/landing/personal_cv.pdf' class="">CV</a>
        <a href='https://scholar.google.com/citations?hl=en&user=IwIWKPYAAAAJ' class="">Scholar</a>
        <a href='https://github.com/ASzot' class="">GitHub</a>
        <a href='/posts' class="">Posts</a>
        <a href="javascript:void(0);" class="menu-item theme-switch" title="">
          <i class="fas fa-adjust fa-fw"></i>
        </a>
      </div>
    </div>
  </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="inner" style='display: flex'>
              <a href='/'>
                <h1>Andrew Szot</h1>
              </a>
              <img id='me-picture' src='/landing/me.jpg'>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/landing/personal_cv.pdf" title="CV">CV</a><a class="menu-item" href="https://github.com/aszot" title="" rel="noopener noreffer" target="_blank">GitHub</a><a class="menu-item" href="/posts" title="Posts">Posts</a><a class="menu-item" href="https://scholar.google.com/citations?hl=en&amp;user=IwIWKPYAAAAJ" title="Scholar" rel="noopener noreffer" target="_blank">Scholar</a><a href="javascript:void(0);" class="menu-item theme-switch" title="">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main"><div class="toc" id="toc-auto">
            <h2 class="toc-title"></h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Training Parallelism</h1><div class="post-meta">
            <div class="post-meta-line"></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2024-08-25">2024-08-25</time>&nbsp;</div>
        </div><div class="details toc open" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Content</span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#background---simple-training-loop">Background - Simple Training Loop</a></li>
    <li><a href="#data-parallel---scaling-batch-size">Data Parallel - Scaling Batch Size</a></li>
    <li><a href="#sharded-optimizer---save-gpu-memory">Sharded Optimizer - Save GPU Memory</a></li>
    <li><a href="#fully-sharded-data-parallel---scaling-model-size">Fully Sharded Data Parallel - Scaling Model Size</a></li>
    <li><a href="#sequence-and-tensor-parallel---scaling-context-length">Sequence and Tensor Parallel - Scaling Context Length</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#acknowledgements">Acknowledgements</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="intro">Intro</h2>
<p>This post shows how to scale training transformer models in terms of batch size, model size and sequence length. First, this post goes over scaling the batch size with multi-GPU and multi-node training. Next, the post details how to scale the model size with training a 7B parameter LLM where training does not fit on a single GPU, but can be trained on 2 GPUs. Finally, the post discusses scaling to a 10,000 token context length when the activations do not on a single GPU.</p>
<p>The code is concise and implemented in pure PyTorch with the potential for scaling to multi-GPU, multi-node, big parameter counts, and long sequence lengths. The code for this post is at <a href="https://github.com/ASzot/training-parallelism" target="_blank" rel="noopener noreffer">github.com/ASzot/training-parallelism</a>.</p>
<h2 id="background---simple-training-loop">Background - Simple Training Loop</h2>
<p>We will use the Llama-2 transformer architecture which uses RoPE positional embeddings, RMSNorm, and SwiGLU activations in the feed forward network with a 1.5x larger hidden dimension. The model code is at <a href="https://github.com/ASzot/training-parallelism/common.py" target="_blank" rel="noopener noreffer">this link</a> and is omitted from this post. In addition, to creating a model with this architecture, the training script also creates a tokenizer using the <code>tiktok</code> library and sets up a simple dataset iterator for the TinyStories dataset. The TinyStories dataset is only a 1.2GB text file and is automatically downloaded if not present. We only run 10 updates just to analyze the training speeds and GPU usage.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&#34;gpt2&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="s2">&#34;cuda&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">LanguageModel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">vocab_size</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_ctx_len</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">context_len</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">embed_dim</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_heads</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_layers</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">tensor_parallel_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Model has </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> parameters&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Load the Tiny Stories training dataset. If it is not downloaded, it is</span>
</span></span><span class="line"><span class="cl"><span class="c1"># automatically downloaded.</span>
</span></span><span class="line"><span class="cl"><span class="n">train_name</span> <span class="o">=</span> <span class="s2">&#34;TinyStories-train&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">load_dataset</span><span class="p">(</span><span class="n">train_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># `train_data_gen` is an iterator that returns numpy array of shape</span>
</span></span><span class="line"><span class="cl"><span class="c1"># `[batch_size, context_len]` representing the tokenized data.</span>
</span></span><span class="line"><span class="cl"><span class="n">train_data_gen</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_name</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokenizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Sample sequences of length context_len+1 so we have the next token target</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># for prediction.</span>
</span></span><span class="line"><span class="cl">    <span class="n">seq_length</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">context_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Start memory and timing collection statistics.</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Run the model training for 10 updates.</span>
</span></span><span class="line"><span class="cl"><span class="n">TOTAL_UPDATES</span> <span class="o">=</span> <span class="mi">10</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">update_i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_data_gen</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Train the model to predict the next token.</span>
</span></span><span class="line"><span class="cl">    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">rearrange</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="s2">&#34;b t d -&gt; (b t) d&#34;</span><span class="p">),</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">batch</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="s2">&#34;b t -&gt; (b t)&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Update=</span><span class="si">{</span><span class="n">update_i</span><span class="si">}</span><span class="s2">, Loss=</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">update_i</span> <span class="o">==</span> <span class="n">TOTAL_UPDATES</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">break</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Log the time and amount of GPU memory for the training loop.</span>
</span></span><span class="line"><span class="cl"><span class="n">tokens_per_second</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="n">world_size</span> <span class="o">*</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">cfg</span><span class="o">.</span><span class="n">context_len</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Memory in GB.</span>
</span></span><span class="line"><span class="cl"><span class="n">max_mem</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1_000_000_000</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">tokens_per_second</span><span class="si">=:</span><span class="s2">,</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">max_mem</span><span class="si">=:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">gb&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>Then run the following to train with a model with 246M parameters for 10 updates (which only takes a couple seconds to run). For this post, I ran everything on NVIDIA A40 GPUs.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python main.py <span class="nv">embed_dim</span><span class="o">=</span><span class="m">1024</span> <span class="nv">n_heads</span><span class="o">=</span><span class="m">8</span> <span class="nv">n_layers</span><span class="o">=</span><span class="m">16</span> <span class="nv">batch_size</span><span class="o">=</span><span class="m">128</span> <span class="nv">context_len</span><span class="o">=</span><span class="m">256</span>
</span></span></code></pre></div><p>This runs at 508,829 tokens-per-second with 35.37gb GPU memory use.</p>
<h2 id="data-parallel---scaling-batch-size">Data Parallel - Scaling Batch Size</h2>
<p>We need a larger batch size to scale up training, but there is no more room on the GPU to increase the batch size. Data distributed parallel (DDP) solves this issue by training on multiple GPUs. DDP runs the same model under different data batches on each GPU and then averages the gradients to learn from all examples. We use <code>torchrun</code> for DDP in PyTorch. <code>torchrun</code> launches the same job in multiple processes each running on a separate GPU. <code>torchrun</code> sets job information via environment variables with <code>LOCAL_RANK</code> for the GPU the process is running on in the current node and <code>WORLD_SIZE</code> for the number of workers. To enable DDP, we add the following code to the existing script.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># ... imports (omitted)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Check if we launched with `torchrun` for distributed training.</span>
</span></span><span class="line"><span class="cl"><span class="n">is_distrib</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="s2">&#34;LOCAL_RANK&#34;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">is_distrib</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Fetch information set by torchrun.</span>
</span></span><span class="line"><span class="cl">    <span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;WORLD_SIZE&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;LOCAL_RANK&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;RANK&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;Starting worker </span><span class="si">{</span><span class="n">rank</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2"> with master address </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> on port </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Set info for just a single worker.</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">world_size</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">is_distrib</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="s2">&#34;nccl&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Use the GPU specified by the rank.</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ... model creation code (omitted)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">is_distrib</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Starting data parallel&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ... remaining training loop (omitted)</span>
</span></span></code></pre></div><p>Then run the following command to now train on 2 GPUs:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">torchrun --nproc_per_node<span class="o">=</span><span class="m">2</span> main.py <span class="nv">embed_dim</span><span class="o">=</span><span class="m">1024</span> <span class="nv">n_heads</span><span class="o">=</span><span class="m">8</span> <span class="nv">n_layers</span><span class="o">=</span><span class="m">16</span> <span class="nv">batch_size</span><span class="o">=</span><span class="m">128</span> <span class="nv">context_len</span><span class="o">=</span><span class="m">256</span>
</span></span></code></pre></div><p>And this gives 1,055,883, tokens-per-second with 35.86gb GPU memory use. In addition to scaling to multiple GPUs on a single node, <code>torchrun</code> and DDP allow scaling to multiple nodes without any code changes. Say you have two nodes with IP addresses <code>node1.com</code> and <code>node2.com</code>. Then on both of the nodes run:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">torchrun --nproc_per_node<span class="o">=</span><span class="m">1</span> --rdzv-id<span class="o">=</span><span class="m">12345</span> --rdzv-backend<span class="o">=</span>c10d --rdzv-endpoint<span class="o">=</span>node1.com:29401 --nnodes<span class="o">=</span><span class="m">2</span> main.py
</span></span></code></pre></div><p>This starts training with 1 GPU on both of the nodes. The choice of <code>node1</code> for the endpoint was arbitrary. Port 29401 was also arbitrary, but needs to be open on both machines. The ID of 12345 can be anything, but needs to be shared between all of the jobs. Typically jobs are launched via a cluster scheduling program like Slurm. Slurm provides info about endpoints and job IDs that can be used to set this information.</p>
<h2 id="sharded-optimizer---save-gpu-memory">Sharded Optimizer - Save GPU Memory</h2>
<p>In standard DDP, everything is replicated between each GPU, meaning the gradients and optimizer state are also replicated across GPUs. However, this is redundant, the gradients and optimizer states can be partitioned per-device with no additional communication overhead. How this generally works is that the each device computes gradients or optimizer states for the entire model for its current data batch. The state is then set to the partition that owns that partition of the gradients or optimizer states. The data from all devices is then reduced on the GPU that owns the partition. This technique is described in more detail <a href="https://arxiv.org/abs/1910.02054" target="_blank" rel="noopener noreffer">ZeRO paper</a> and to use it with PyTorch, simply change the optimizer setup to:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># ... Rest of code omitted</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.distributed.optim</span> <span class="kn">import</span> <span class="n">ZeroRedundancyOptimizer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">zero_opt</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">ZeroRedundancyOptimizer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">optimizer_class</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ... Rest of code omitted</span>
</span></span></code></pre></div><p>Now running training on 2 GPUs as before with:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">torchrun --nproc_per_node<span class="o">=</span><span class="m">2</span> main.py <span class="nv">embed_dim</span><span class="o">=</span><span class="m">1024</span> <span class="nv">n_heads</span><span class="o">=</span><span class="m">8</span> <span class="nv">n_layers</span><span class="o">=</span><span class="m">16</span> <span class="nv">batch_size</span><span class="o">=</span><span class="m">128</span> <span class="nv">context_len</span><span class="o">=</span><span class="m">256</span> <span class="nv">zero_opt</span><span class="o">=</span>True
</span></span></code></pre></div><p>This gives 35.37gb GPU memory use, which is a slight memory saving over the previous result. The memory savings for this technique are greater as the model size, and thus the optimizer and gradients increase in size.</p>
<h2 id="fully-sharded-data-parallel---scaling-model-size">Fully Sharded Data Parallel - Scaling Model Size</h2>
<p>Now we will scale training to a 7.2 billion parameter model. This requires setting the parameters <code>embed_dim=4096 n_heads=32 n_layers=48</code> for launching the job. Is this model small enough to fit on the A40 GPU which has 46gb of GPU memory? To find out, first calculate that the memory for the model and the gradients will be <code>4 * num_model_params</code> (parameters, gradients, Adam momentum, Adam variance). The memory for the activations of the model is is <code>6 * embed_dim + heads*context_len</code> for each transformer layer where the 6 comes from the 3 QKV projections, 2 from the FFN, and 1 from the final linear projection. This is only a rough estimate as it ignores the expansion factor in the Llama FFN layer. There is also an added <code>2 * num_tokens</code> for the embedding and output layers. This is then scaled by the number of tokens in the batch which is <code>batch_size * context_len</code>. We thus have:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">num_tokens</span> <span class="o">=</span> <span class="mi">50257</span> <span class="c1"># The number of tokens for the GPT-2 tokenizer we are using.</span>
</span></span><span class="line"><span class="cl"><span class="n">num_model_params</span> <span class="o">=</span> <span class="mi">7_257_206_784</span> <span class="c1"># Retrieved from creating the model.</span>
</span></span><span class="line"><span class="cl"><span class="n">activations</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">context_len</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">num_tokens</span><span class="o">+</span><span class="n">n_layers</span><span class="o">*</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="n">embed_dim</span><span class="o">+</span><span class="n">n_heads</span><span class="o">*</span><span class="n">context_len</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Multiply by 2 for 2 bytes per-param for bfloat16 format.</span>
</span></span><span class="line"><span class="cl"><span class="n">training_mem_gb</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">num_model_params</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">activations</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">1_000_000_000</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">training_mem_gb</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>This gives 59.77gb, greater than the 46gb of A40 GPU memory, so no, the training will not fit on the GPU. To resolve this, we partition the model parameters, meaning the parameters of the model are split up between the GPUs. We can then train larger models by using more GPUs. Fully sharded data parallel (FSDP) in PyTorch provides this functionality. This is implemented via the following code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.distributed.fsdp</span> <span class="kn">import</span> <span class="n">FullyShardedDataParallel</span> <span class="k">as</span> <span class="n">FSDP</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">fsdp</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Starting FSDP&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">FSDP</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">auto_wrap_policy</span><span class="o">=</span><span class="n">ModuleWrapPolicy</span><span class="p">({</span><span class="n">CausalTransformerLayer</span><span class="p">}),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">elif</span> <span class="n">is_distrib</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Starting data parallel&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></span></code></pre></div><p><code>auto_wrap_policy=ModuleWrapPolicy({CausalTransformerLayer})</code> indicates what is sharded between the GPUs and is necessary to specify in this case. Printing the resulting model we see:</p>
<pre tabindex="0"><code>FullyShardedDataParallel(
  (_fsdp_wrapped_module): LanguageModel(
    (tok_embed): Embedding(50257, 4096)
    (rope): RoPE_Embedding()
    (blocks): Sequential(
      (0): FullyShardedDataParallel(
        (_fsdp_wrapped_module): CausalTransformerLayer(
          (qkv_proj): Linear(in_features=4096, out_features=12288, bias=False)
          (att_out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (att_norm): RMSNorm()
          (ffn_norm): RMSNorm()
          (ffn): FFN(
            (up_proj): Linear(in_features=4096, out_features=6144, bias=False)
            (gate_proj): Linear(in_features=4096, out_features=6144, bias=False)
            (down_proj): Linear(in_features=6144, out_features=4096, bias=False)
          )
          (rope): RoPE_Embedding()
        )
      )
      (1): FullyShardedDataParallel(
        (_fsdp_wrapped_module): CausalTransformerLayer(
          (qkv_proj): Linear(in_features=4096, out_features=12288, bias=False)
          (att_out_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (att_norm): RMSNorm()
          (ffn_norm): RMSNorm()
          (ffn): FFN(
            (up_proj): Linear(in_features=4096, out_features=6144, bias=False)
            (gate_proj): Linear(in_features=4096, out_features=6144, bias=False)
            (down_proj): Linear(in_features=6144, out_features=4096, bias=False)
          )
          (rope): RoPE_Embedding()
        )
      )
      ...
</code></pre><p><code>FullyShardedDataParallel</code> wrapping each individual layer means that these layers are what is sharded between GPUs. If <code>auto_wrap_policy</code> is not specified, only the external <code>LanguageModel</code> would be wrapped in <code>FullyShardedDataParallel</code>, meaning the individual layers are sharded between GPUs and thus none of the model parameters are sharded, resulting in no memory savings. Another important aspect of FSDP is that everything must be a <code>nn.Module</code> and all model forward logic must take place in the <code>forward</code> method, rather than a function that operates on the module, because FSDP will wrap the module in the <code>FullyShardedDataParallel</code> wrapper. To see the benefits of FSDP, run the following:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">2</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="n">fsdp</span><span class="o">=</span><span class="kc">True</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">4096</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">32</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">48</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span>
</span></span></code></pre></div><p>Which gives 13,111 tokens per second and 36.33gb GPU memory usage for training the 7b parameter model, whereas before the model training ran out of memory. By turning off the model partitioning, FSDP also turns into regular DDP. This is achieved by setting:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sharding_strategy</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">ShardingStrategy</span><span class="o">.</span><span class="n">FULL_SHARD</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">shard_strategy</span> <span class="o">==</span> <span class="s2">&#34;full&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="n">ShardingStrategy</span><span class="o">.</span><span class="n">NO_SHARD</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">FSDP</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">sharding_strategy</span><span class="o">=</span><span class="n">sharding_strategy</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">auto_wrap_policy</span><span class="o">=</span><span class="n">ModuleWrapPolicy</span><span class="p">({</span><span class="n">CausalTransformerLayer</span><span class="p">}),</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h2 id="sequence-and-tensor-parallel---scaling-context-length">Sequence and Tensor Parallel - Scaling Context Length</h2>
<p>The previous models were trained with a short context length of 256. How can we scale training to a longer context length of 10,000 without running out of memory? Running the following results in OOM on 2xA40 GPUs:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">torchrun --nproc_per_node<span class="o">=</span><span class="m">2</span> main.py <span class="nv">context_len</span><span class="o">=</span><span class="m">10000</span> <span class="nv">embed_dim</span><span class="o">=</span><span class="m">1024</span> <span class="nv">batch_size</span><span class="o">=</span><span class="m">4</span> <span class="nv">fsdp</span><span class="o">=</span>True <span class="nv">shard_strategy</span><span class="o">=</span>no
</span></span></code></pre></div><p>The solution is to use <em>sequence and tensor parallelism</em> where matrix multiplications are partitioned per GPU. Section 3 of the <a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener noreffer">Megatron-LM paper</a> describes the idea best, and I will briefly summarize the idea here. Let $ N$ be the sequence length, $D $ the hidden dimension, $ X \in \mathbb{R}^{N \times D}$ the input tensor (ignoring batch dimension) and $ W \in \mathbb{R}^{D \times D}$ be weight parameters for a linear layer. Then the linear projection $ X W $ can be rewritten by first splitting $ W$ &ldquo;columnwise&rdquo; into $ W = \left[ W_1, W_2 \right] $ where $ W_1 \in \mathbb{R}^{D \times D_1}, W_2 \in \mathbb{R}^{D \times D_2}$ and then computing $ \left[ X W_1, X W_2 \right] $ where  these two operations can be done in parallel per device and the result is the same as $ XW$.</p>
<p>To apply this idea to the attention operation, we columnwise partition the query, key, and value projections $ Q, K, V \in \mathbb{R}^{D \times D} $ into $ Q = [Q_1, Q_2], K = [K_1, K_2], V = [V_1, V_2] $. For input $ X \in \mathbb{R}^{N \times D}$, we then compute attention as normal (ignoring multi-head outputs in the notation) with $ A_i = \text{softmax}\left( \frac{(XQ_i) (XK_i)^\top}{\sqrt{D_i}} \right) V_i \in \mathbb{R}^{N \times D_i}$. Each $ A_i $ only involves hidden dimensions $ D_i$ and can be computed independently of other $ A_i$. For the output projection, $ W^{O} \in \mathbb{R}^{D \times D}$ we could reduce $ \left[   A_1, A_2 \right]  \rightarrow  A$ and then compute $ A W^{O}$, but we can avoid this reduce by computing $ A_i W^{O}_i$ separately where $ W^{O}_i \in \mathbb{R}^{D_i \times D}$  is now partitioned <strong>&ldquo;rowwise&rdquo;</strong>. Finally, we reduce outputs $ \left[ A_1 W^{O}_1, A_2 W^{O}_2 \right] $. This description was for 2 partition elements, but the same technique works exactly the same for more partition elements. Tensor parallelism is also applied in the same way to the FFN network.</p>
<p>In PyTorch, tensor parallelism works by setting up a device mesh, which is like the previous <code>dist.init_process_group</code> call, but with more control over the setup. The distributed setup code is now:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">fsdp</span> <span class="ow">and</span> <span class="n">use_tp</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># This must be before the model creation to properly set the GPU device ID</span>
</span></span><span class="line"><span class="cl">    <span class="n">dp_size</span> <span class="o">=</span> <span class="n">world_size</span> <span class="o">//</span> <span class="n">cfg</span><span class="o">.</span><span class="n">tensor_parallel_size</span>
</span></span><span class="line"><span class="cl">    <span class="n">tp_size</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">tensor_parallel_size</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># This is in place of `init_process_group` for more complex sharding</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># strategies.</span>
</span></span><span class="line"><span class="cl">    <span class="n">device_mesh</span> <span class="o">=</span> <span class="n">init_device_mesh</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="n">dp_size</span><span class="p">,</span> <span class="n">tp_size</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># The mesh names are arbitrary. The only things that matters is how we</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># use these meshes. The &#34;dp&#34; mesh is passed to FSDP and</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># the &#34;tp&#34; mesh is passed to the model parallelization.</span>
</span></span><span class="line"><span class="cl">        <span class="n">mesh_dim_names</span><span class="o">=</span><span class="p">(</span><span class="s2">&#34;dp&#34;</span><span class="p">,</span> <span class="s2">&#34;tp&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">elif</span> <span class="n">is_distrib</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="s2">&#34;nccl&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Use the GPU specified by the rank.</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">device_mesh</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="k">elif</span> <span class="n">use_tp</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;fsdp must be `True` when setting </span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">tensor_parallel_size</span><span class="si">=}</span><span class="s2">.&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>After initializing the model, we parallelize the attention and FFN layers of each attention block in the model. Furthermore, the RMSNorm normalization operation can also be sharded over the sequence dimension. The following code sets up this parallelization.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tp_mesh</span> <span class="o">=</span> <span class="n">device_mesh</span><span class="p">[</span><span class="s2">&#34;tp&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">fsdp_device_mesh</span> <span class="o">=</span> <span class="n">device_mesh</span><span class="p">[</span><span class="s2">&#34;dp&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Keys of the TP plan must be the same module names in `model` (as how they</span>
</span></span><span class="line"><span class="cl"><span class="c1"># are saved in the `state_dict` for example).</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">parallelize_module</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">module</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">device_mesh</span><span class="o">=</span><span class="n">tp_mesh</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallelize_plan</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Partition the input embeddings (each row is a different token).</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;tok_embed&#34;</span><span class="p">:</span> <span class="n">RowwiseParallel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># For each module, we specify how the inputs will be sharded</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># where `Replicate()` means not sharded (they are repeated on</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># every device), and `Shard(1)` means they are sharded along</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># sequence dimension.</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_layouts</span><span class="o">=</span><span class="n">Replicate</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">output_layouts</span><span class="o">=</span><span class="n">Shard</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;output_norm&#34;</span><span class="p">:</span> <span class="n">SequenceParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;lm_head&#34;</span><span class="p">:</span> <span class="n">ColwiseParallel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_layouts</span><span class="o">=</span><span class="n">Shard</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">output_layouts</span><span class="o">=</span><span class="n">Replicate</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Parallelize each transformer layer.</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallelize_module</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">module</span><span class="o">=</span><span class="n">block</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">device_mesh</span><span class="o">=</span><span class="n">tp_mesh</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">parallelize_plan</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;att_norm&#34;</span><span class="p">:</span> <span class="n">SequenceParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ffn_norm&#34;</span><span class="p">:</span> <span class="n">SequenceParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Attention.</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;attention&#34;</span><span class="p">:</span> <span class="n">PrepareModuleInput</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">input_layouts</span><span class="o">=</span><span class="p">(</span><span class="n">Shard</span><span class="p">(</span><span class="mi">1</span><span class="p">),),</span>
</span></span><span class="line"><span class="cl">                <span class="n">desired_input_layouts</span><span class="o">=</span><span class="p">(</span><span class="n">Replicate</span><span class="p">(),),</span>
</span></span><span class="line"><span class="cl">            <span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;attention.q_proj&#34;</span><span class="p">:</span> <span class="n">ColwiseParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;attention.k_proj&#34;</span><span class="p">:</span> <span class="n">ColwiseParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;attention.v_proj&#34;</span><span class="p">:</span> <span class="n">ColwiseParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;attention.att_out_proj&#34;</span><span class="p">:</span> <span class="n">RowwiseParallel</span><span class="p">(</span><span class="n">output_layouts</span><span class="o">=</span><span class="n">Shard</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># FFN.</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ffn&#34;</span><span class="p">:</span> <span class="n">PrepareModuleInput</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">input_layouts</span><span class="o">=</span><span class="p">(</span><span class="n">Shard</span><span class="p">(</span><span class="mi">1</span><span class="p">),),</span>
</span></span><span class="line"><span class="cl">                <span class="n">desired_input_layouts</span><span class="o">=</span><span class="p">(</span><span class="n">Replicate</span><span class="p">(),),</span>
</span></span><span class="line"><span class="cl">            <span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ffn.up_proj&#34;</span><span class="p">:</span> <span class="n">ColwiseParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ffn.gate_proj&#34;</span><span class="p">:</span> <span class="n">ColwiseParallel</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ffn.down_proj&#34;</span><span class="p">:</span> <span class="n">RowwiseParallel</span><span class="p">(</span><span class="n">output_layouts</span><span class="o">=</span><span class="n">Shard</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">        <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><p>To work with these different sharding strategies between the different modules, we specify the sharding format the the input and output of the Modules via <code>input_layouts</code> and <code>desired_input_layouts</code>. <code>Replicate()</code> means the tensor is not sharded and replicated per-device. <code>Shard(dim=1)</code> means the tensor is sharded, and on the sequence dimension, which is what the <code>dim=1</code> refers to (recall the tensors have shape $B \times N \times D$). The FSDP initialization also must be slightly modified to account for the new data parallel device mesh:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">fsdp</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Wrapping model in fsdp&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">sharding_strategy</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">ShardingStrategy</span><span class="o">.</span><span class="n">FULL_SHARD</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">shard_strategy</span> <span class="o">==</span> <span class="s2">&#34;full&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span> <span class="n">ShardingStrategy</span><span class="o">.</span><span class="n">NO_SHARD</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">FSDP</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">sharding_strategy</span><span class="o">=</span><span class="n">sharding_strategy</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">auto_wrap_policy</span><span class="o">=</span><span class="n">ModuleWrapPolicy</span><span class="p">({</span><span class="n">CausalTransformerLayer</span><span class="p">}),</span>
</span></span><span class="line"><span class="cl">        <span class="c1">####################</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># For TP</span>
</span></span><span class="line"><span class="cl">        <span class="n">device_mesh</span><span class="o">=</span><span class="n">fsdp_device_mesh</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_orig_params</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="c1">####################</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">elif</span> <span class="n">is_distrib</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Starting data parallel&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></span></code></pre></div><p>Now we are able to train with a sequence length of 10,000 by using a tensor parallelism factor of 2 without running out of GPU memory.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">torchrun --nproc_per_node<span class="o">=</span><span class="m">2</span> main.py <span class="nv">context_len</span><span class="o">=</span><span class="m">10000</span> <span class="nv">embed_dim</span><span class="o">=</span><span class="m">1024</span> <span class="nv">batch_size</span><span class="o">=</span><span class="m">4</span> <span class="nv">fsdp</span><span class="o">=</span>True <span class="nv">shard_strategy</span><span class="o">=</span>no <span class="nv">tensor_parallel_size</span><span class="o">=</span><span class="m">2</span>
</span></span></code></pre></div><p>This gives 1,992,486 tokens per second and 30.85gb GPU usage.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The following techniques are combined into a compact <a href="https://github.com/ASzot/training-parallelism" target="_blank" rel="noopener noreffer">codebase here</a> that scales to large batch sizes, model parameter counts, and sequence lengths across multiple GPUs and nodes.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/fsdp.html" target="_blank" rel="noopener noreffer">https://pytorch.org/docs/stable/fsdp.html</a> FSDP setting explanations.</li>
<li><a href="https://pytorch.org/tutorials/intermediate/TP_tutorial.html" target="_blank" rel="noopener noreffer">https://pytorch.org/tutorials/intermediate/TP_tutorial.html</a> Useful example of applying tensor parallelism to a language model.</li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();"></a></span>&nbsp;|&nbsp;<span><a href="/"></a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/position_embeddings/" class="prev" rel="prev" title="Position Embeddings"><i class="fas fa-angle-left fa-fw"></i>Position Embeddings</a></div>
</div>
</article></main><footer class="footer">
        <div class="footer-container"><div class="footer-line">
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i>
                    Andrew Szot<span itemprop="copyrightYear"> 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
