<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title> - Andrew Szot</title>
        <link>https://www.andrewszot.com/posts/</link>
        <description> | Andrew Szot</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 25 Jun 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://www.andrewszot.com/posts/" rel="self" type="application/rss+xml" /><item>
    <title>KV Cache</title>
    <link>https://www.andrewszot.com/posts/kv_cache/</link>
    <pubDate>Tue, 25 Jun 2024 00:00:00 &#43;0000</pubDate>
    <author></author>
    <guid>https://www.andrewszot.com/posts/kv_cache/</guid>
    <description><![CDATA[Intro The Key-Value (KV) cache is used to speed up next token prediction in transformer models. For example, when large language models (LLMs) are generating text, the KV cache stores the model&rsquo;s activations for previously generated text to efficiently generate the next token. While not used during training, the KV cache is a crucial implementation detail for fast transformer inference. In this post, I go over KV cache implementation details and show that it results in a $20\times$ inference speedup over naive transformer inference.]]></description>
</item><item>
    <title>Practical Challenges of Imitation Learning from Observation</title>
    <link>https://www.andrewszot.com/posts/on_lfo/</link>
    <pubDate>Sun, 30 Aug 2020 00:00:00 &#43;0000</pubDate>
    <author></author>
    <guid>https://www.andrewszot.com/posts/on_lfo/</guid>
    <description><![CDATA[Overview In this post, I will explore some practical details in popular imitation learning from observation methods. Learning from observation (LfO) is the problem of learning a policy from a set of state-only expert demonstrations. The goal of LfO is to eventually enable agents to learn by observing humans or other robots. However, LfO is difficult because it both requires learning perception of what the expert is doing, and then learning a control policy on top of this learned perception.]]></description>
</item><item>
    <title>Voice Conversion</title>
    <link>https://www.andrewszot.com/posts/voice_conversion/</link>
    <pubDate>Tue, 28 Nov 2017 00:00:00 &#43;0000</pubDate>
    <author></author>
    <guid>https://www.andrewszot.com/posts/voice_conversion/</guid>
    <description><![CDATA[How well can we convert speech between people&rsquo;s voices? By: Andrew Szot, Arshdeep Singh, Md Nasir, Sriram Somasundaram
Introduction Recently, there have been many exciting results in computer vision with the introduction of deeper convolutional models that encode higher dimensional and interpretable features (neural style) [1]. In contrast, deep and thorough understanding of speech has suffered from the lack of deep learning models catering to audio signals. For a while, traditional audio processing techniques remained dominant over deep learning approaches in terms of audio classification and detection.]]></description>
</item></channel>
</rss>
